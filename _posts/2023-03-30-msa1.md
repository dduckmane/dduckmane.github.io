---
layout: single
title:  "Kafka"
categories: MSA
tag: [개념]

author_profile: false
sidebar:
    nav: "counts"
---

# Kafka에 대해 알아보자

## Kafka란

- 데이터 동기화
- 각각의 서비스들이 각각 데이터베이스를 사용한다고 가정을 한다면 서로 동기화가 필요
- 확장 가능한 작업을 위해 데이터 피드의 분산 스트리밍, 파이프 라이닝 및 재생을 위한 실시간 스트리밍 데이터를 처리하기 위한 목적으로 설계된 오픈 소스 분산형 게시-구독 메시징 플랫폼

## 구성 요소

- 브로커 : 브로커라 카프카 서버로서 보토 3대 이상 클러스터로 구성이 된다.
- zookeeper : 다수의 브로커 서버를 관리해주는 코디네이터
- 프로듀서 : 메시지를 전달하는 주체
- 컨슈머: 메시지를 받는 주체
- 토픽 : 브로커 안에 생성, 프로듀서는 토픽에 메시지를 전달하고 토픽을 구독한 컨슈머는 메시지를 받는다.

## 흐름

- 코디네이터(주키퍼) 를 실행
- 브로커(카프카 서버)를 실행
- 브로커에 토픽을 생성
- producer 가 토픽에게 메시지를 전달
- 구독한 컨슈머는 메시지를 수신

## Kafka Connect

![image](https://user-images.githubusercontent.com/108928206/228863762-f0fc69f7-5a33-42ed-8ae5-fbb110aa72e9.png)

- kafka 를 통해서 데이터 베이스끼리 통신을 할 수가 있다.
- 그러기 위해서 필요한 것이 Kafka Connect이다. confluent 가 예시이다.
- 그래서 confluent 를 통해서 Kafka Connect Source 와 Kafka Connect Sink 역할을 하고
- jdbc 를 이용하기 위해서 mariadb-java-client가 필요하다.
- Kafka Connect Source가 데이터를 토픽으로 전달하고 Kafka Connect Sink가 토픽의 데이터를 db 에 전달한다.

